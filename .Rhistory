type = "bar") %>% # Telling R that we want a bar plot
layout(xaxis = list(title = ""), # Adding name to the x-axis, an empty string "" gives no name
yaxis = list(title = "Share of adult population with the right to vote"), # Adding name to y-axis
plot_bgcolor = "lightgrey") # Setting the background color of the plot to light grey
vdem2 %>%
mutate(v2casoe_1 = ifelse(v2casoe_1 < 0.5, "Emergency", "Non-emergency")) %>% # Recoding the v2casoe_1 variable to become "Emergency" if the value is over 0.5 and "Non-emergency" if the value is below 0.5
drop_na(v2casoe_1) %>% # Removing all missing variables from the v2casoe_1 variable
plot_ly(x = ~v2elsuffrage, # Setting the percentage of the population with suffrage to x-axis
y = ~v2regsupgroupssize_mean, # Percentage of population in regime main supporting group on y-axis
color = ~v2casoe_1, # Setting the colors of the dots to whether there was an emergency
colors = c("blue", "orange"), # Specifying colors to blue and orange
text = ~paste(country_name, year), # Adding a variable used to hover over the dots, pasting together values from the country_name variable and year variable
hoverinfo = "text", # Using this hoverinfo variable to display when hovering over dots
type = "scatter", # Telling R that we want a scatterplot
mode = "markers", # Telling R that we want dots, not lines
alpha = 0.2) %>% # Adding some dot transparency
layout(xaxis = list(title = "Share of adult population with the right to vote"),
yaxis = list(title = "Percentage of population in regime main supporting group"))
vdem2 %>%
filter(country_name == "Norway") %>%
plot_ly(x = ~year,
y = ~v2regsupgroupssize_mean,
name = "Percentage of population in regime main supporting group", # Giving name to the line being plotted
type = "scatter",
mode = "lines") %>% # Specifying that we want lines
add_lines(y = ~v2elsuffrage, # Add an extra line to the plot, plotting the variable v2elsuffrage as well
name = "Percentage of adult population with the right to vote", # Giving name to the second line being plotted
mode = 'lines') %>% # Specifying that this should be lines, not markers (dots)
layout(xaxis = list(title = ""),
yaxis = list(title = ""),
legend = list(orientation = "v", # Wanting the legend to list the categories vertically ("v")
x = 0, y = 1.1)) # Placing the legend at these coordinates in the plot (play around to find the right customization)
vdem2 %>%
mutate(v2casoe_1 = ifelse(v2casoe_1 < 0.5, "Emergency", "Non-emergency")) %>%
plot_ly(x = ~v2casoe_1,
y = ~v2regsupgroupssize_mean,
type = "box") %>%
layout(xaxis = list(title = ""),
yaxis = list(title = "Percentage of population in regime main supporting group"))
vdem2 %>%
mutate(v2casoe_1 = ifelse(v2casoe_1 < 0.5, "Emergency", "Non-emergency")) %>%
plot_ly(x = ~v2casoe_1,
y = ~v2regsupgroupssize_mean,
type = "box") %>%
layout(xaxis = list(title = ""),
yaxis = list(title = "Percentage of population in regime main supporting group"))
plot <- vdem2 %>%
filter(country_name %in% c("Spain", "Portugal", "Italy", "Greece")) %>%
filter(year %in% c(1880, 1950, 1980)) %>%
ggplot(aes(x = country_name,
y = v2elsuffrage,
fill = factor(year))) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "",
y = "Share of adult population with the right to vote")
ggplotly(plot)
install.packages("DT")
install.packages("DT")
library(DT)
vdem_table <- vdem2 %>%
filter(country_name == "Norway") %>%
filter(year %in% c(1790, 1890, 1990)) %>%
select(year, v2elsuffrage) %>%
rename("Percentage with suffrage" = v2elsuffrage)
DT::datatable(vdem_table,
rownames = FALSE,
caption = "Development of suffrage in Norway over 200 years")
DT::datatable(vdem_table,
rownames = FALSE,
caption = "Development of suffrage in Norway over 200 years")
library(DT)
DT::datatable(vdem_table,
rownames = FALSE,
caption = "Development of suffrage in Norway over 200 years")
install.packages("DT")
install.packages("DT")
install.packages("dbplyr")
install.packages("dbplyr")
DT::datatable(vdem_table,
rownames = FALSE,
caption = "Development of suffrage in Norway over 200 years")
library(dbplyr)
DT::datatable(vdem_table,
rownames = FALSE,
caption = "Development of suffrage in Norway over 200 years")
install.packages("flexdashboard")
for(x in unique(sessions_storting$id)){
for(x in unique(sessions_storting$id)){
a <- get_session_questions(sessionid = x, q_type = "interpellasjoner", status = NA, good_manners = 0)
b <- get_session_questions(sessionid = x, q_type = "sporretimesporsmal", status = NA, good_manners = 0)
c <- get_session_questions(sessionid = x, q_type = "skriftligesporsmal", status = NA, good_manners = 0)
paste0("stortingsporsmal", x) = rbind((a, b, c))
}
paste0("stortingsporsmal", x) = rbind(a, b, c)
for(x in unique(sessions_storting$id)){
a <- get_session_questions(sessionid = x, q_type = "interpellasjoner", status = NA, good_manners = 0)
b <- get_session_questions(sessionid = x, q_type = "sporretimesporsmal", status = NA, good_manners = 0)
c <- get_session_questions(sessionid = x, q_type = "skriftligesporsmal", status = NA, good_manners = 0)
paste0("stortingsporsmal", x) = rbind(a, b, c)
}
a <- get_session_questions(sessionid = "2021-2022", q_type = "interpellasjoner", status = NA, good_manners = 0)
View(a)
b <- get_session_questions(sessionid = "2021-2022", q_type = "sporretimesporsmal", status = NA, good_manners = 0)
View(b)
q <- rbind(a, b)
View(q)
View(a)
for(x in unique(sessions_storting$id)){
a <- get_session_questions(sessionid = x, q_type = "interpellasjoner", status = NA, good_manners = 0)
b <- get_session_questions(sessionid = x, q_type = "sporretimesporsmal", status = NA, good_manners = 0)
c <- get_session_questions(sessionid = x, q_type = "skriftligesporsmal", status = NA, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
a<-list()
b<-list()
c<-list()
for(x in unique(sessions_storting$id)){
a[[x]] <- get_session_questions(sessionid = x, q_type = "interpellasjoner", status = NA, good_manners = 0)
b[[x]] <- get_session_questions(sessionid = x, q_type = "sporretimesporsmal", status = NA, good_manners = 0)
c[[x]] <- get_session_questions(sessionid = x, q_type = "skriftligesporsmal", status = NA, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
View(a)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, message = FALSE)
library(tidyverse)
library(readtext)
txt <- readtext("https://www.dropbox.com/s/ao17b0eldnybx5n/Day11-Text-manipulation-and-text-preprocessing.pdf?dl=1") %>%
# I read in a pdf document using readtext
select(text) %>%
# readtext gives me two variables, doc_id and text, here I choose to select only the text variable
pull() # I extract the text from the variable, creating a vector
txt
comments_trial <- readtext("https://www.dropbox.com/s/as3a62d5g11ts8s/comment_section_depp-heard-trial.txt?dl=1")
glimpse(comments_trial)
comments_trial_text <- comments_trial %>%
select(text) %>% # Getting only the text variable
pull() # Making the variable into a single character vector
comments_substring <- substr(comments_trial_text, 1, 100)
comments_substring # Showing character 1 to 100 of the text.
View(a)
get_question(questionid = "89149", good_manners = 0)
# Fetch parts of a string, here characters from position 1 to position 5
substr(comments_substring, 1, 5)
# Check how many characters are present in a string
str_length(comments_substring)
# Put together two strings. (Equivalent to paste and paste0)
str_c(comments_substring, ". The end.")
# Make all characters into upper case
str_to_upper(comments_substring)
# Make all characters into lower case
str_to_lower(comments_substring)
# Give all words a start capital letter and make the rest lower case
str_to_title(comments_substring)
# Give all sentences a start capital letter and make the rest lower case
str_to_sentence(comments_substring)
# Check if a pattern is part of a string
str_detect(comments_substring, "Johnny Depp")
# Subset the strings that contain a specific pattern
str_subset(comments_substring, "Johnny Depp")
# Check where in the string a specific pattern is located
str_locate(comments_substring, "Johnny Depp")
# Extract only the part of a string that matches a specific pattern
str_extract(comments_substring, "Johnny Depp")
# Remove from the string all instances that match a specific pattern
str_remove(comments_substring, "Johnny Depp")
# Replace patterns of a string with another string
str_replace(comments_substring, "Johnny Depp", "Jack Sparrow")
# Remove whitespace from the start and the end of a string
str_trim(comments_substring)
# Remove whitespace from the start and end of a string, and inside a string
str_squish(comments_substring)
# Make a list of strings by splitting them on a certain pattern
str_split(comments_substring, "\n")
text <- "Here in the company ThreePods, we deliver many services of great quality that make important contributions to you and the world around you. Our service team is always ready to help. John Smith is the head of the service team, and can be reacehd at smith@tp.com. Anne Johnson, Bill Brown and Nico Perez, available at johnson@tp.com, brown@tp.com and perez@tp.com, also work tiredlessly to improve efficiency and quality. If you have questions or comments on this piece of text, you can contact me, Amy Young, at young@tp.com."
str_extract(text, "[a-z]+@tp.com")
str_extract_all(text, "[a-z]+@tp.com")
comments <- comments_trial_text %>%
str_split("\n\n") %>% # Split the text on double lineshift, \n\n
.[[1]] %>% # Pick the first element of the list, as we only have one
str_remove_all("[0-9]+(\\.)?(K)?") %>% # Remove all parts of the string containing numbers, possiblu followed by dot and possibly followed by K
str_remove_all("days ago|hours ago|\\(edited\\)|Pinned by") %>% # Removing these strings from the text, as we're not gathering info on the time of the comments
stringi::stri_remove_empty() %>% # Removing all empty character vectors
str_split("\n") %>% # Splitting again on single lineshift
map(., ~ str_squish(.)) %>% # Removing whitespace from between and within the string, using map because we now have a list of lists
map(., ~ stringi::stri_remove_empty(.)) %>%  # Removing empty character vectors again
map(., ~ unique(.)) # Picking only the unique values
name <- list() # Make a list where we can store the names
text <- list() # Make a list where we can store the text
for (i in 1:length(comments)) { # Creating a for-loop
name[[i]] <- comments[[i]][1] # Picking the first vector element in every list element and store it in the vector called "name"
text[[i]] <- str_c(comments[[i]][-1], collapse = "") # Picking the rest of the elements from the list elements and collapsing them to a single character vector
}
dataframe <- as_tibble(list(name = unlist(name), # Putting the two vectors together into a dataframe
text = unlist(text)))
dataframe <- dataframe %>%
mutate(text = str_remove_all(text, "https://.*"), # In the dataframe, I change the text variable and remove URLs, that is, all strings starting with https:// followed by anything
text = str_conv(text, "ASCII"), # The text has emojis, to remove them I convert the text to ASCII encoding
text = str_replace_all(text, "\uFFFD", "")) # Now all emojis are called UFFFD, and I remove them
dataframe <- dataframe %>%
mutate(name = ifelse(str_length(name) >= 50, NA, name)) %>% # One text ended up in the name columns, I turn it into NA filtering on strings with more than 50 characters
na.omit() # And remove NA from the dataframe
dataframe
questionlist <- unnest(c(a, b, c))
questionlist <- unnest(a)
string <- "  This   is a    string with  whitespace    .  "
string
# Remove whitespace from ends of strings
str_trim(string, side = "both")
# Remove whitespace from ends of strings and in the middle
str_squish(string)
stopwords <- c("i", "is", "are", "we", "him", "her", "such", "they", "and", "a", "for", "be", "as", "will", "to", "your", "our", "these", "this")
# Creating word boundaries by adding \\b in front and behind each word
stopwords_boundary <- str_c("\\b", stopwords, "\\b",
collapse = "|") # Dividing the words by |
string <- "this is a string containing a few stopwords such as a, for and i, and to our common benefit, these will be removed"
str_replace_all(string, stopwords_boundary, "")
string <- "Here we have a string. Is it useful for you? Maybe not... But! With time, it might be."
punctuation <- c("\\!|\\?|\\.|\\,")
str_replace_all(string, punctuation, "")
str_replace_all(string, "[:punct:]", "")
string <- "I have 50 likes on my post. My friends have 100 likes. It's not fair. I want 1000000 likes!"
str_remove_all(string, "[0-9]+")
string <- "I was born on the 1st of October 1993."
str_extract(string, "[0-9]{4}")
symbols <- str_c("\\!|\\@|\\#|\\$|\\%|\\^|\\&|\\*|\\(|\\)|\\{|\\}|\\-|\\=|\\_|\\+|\\:|\\|\\<|\\>|\\?|\\,|\\.|\\/|\\;|\\'|\\[|\\]|\\-=")
string <- "A string must be written in [code] #code-string. Because string - code = just normal text & that, we can simply just read_"
str_remove_all(string, symbols)
string <- "A string must be written in [code] #code-string. Because string - code = just normal text & that, we can simply just read_"
str_replace_all(string, "[^[:alnum:]]", " ")
questionlist <- unlist(a)
rm(questionlist)
questionlist <- unnest(a)
questionlist <- unnest(a, cols = c(`2021-2022`, `2020-2021`, `2019-2020`, `2018-2019`, `2017-2018`,
`2016-2017`, `2015-2016`, `2014-2015`, `2013-2014`, `2012-2013`,
`2011-2012`))
questionlist <- do.call("rbind", a)
View(questionlist)
questionlista <- do.call("rbind", a)
questionlistb <- do.call("rbind", b)
questionlistc <- do.call("rbind", c)
clist <- c(questionlista, questionlistb, questionlistc)
View(clist)
clist <- list(questionlista, questionlistb, questionlistc)
questionlis <- do.call("rbind", clist)
questionlist <- do.call("rbind", clist)
rm(questionlis)
d <- list()
for(x in unique(questionlist$id)){
it <- 100*(which(questionlist$id) == x) / length(unique(questionlist$id)))
cat(paste0(sprintf("Progress: %.4f%%             ", it), "\r"))
d[[x]] <- get_question(questionid = 1, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
for(x in unique(questionlist$id)){
it <- 100*(which(questionlist$id) == x) / length(unique(questionlist$id)))
cat(paste0(sprintf("Progress: %.4f%%             ", it), "\r"))
d[[x]] <- get_question(questionid = 1, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
for(x in unique(questionlist$id)){
it <- 100*(which(unique(questionlist$id) == x) / length(unique(questionlist$id)))
cat(paste0(sprintf("Progress: %.4f%%             ", it), "\r"))
d[[x]] <- get_question(questionid = 1, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
for(x in unique(questionlist$id)){
it <- 100*(which(unique(questionlist$id) == x) / length(unique(questionlist$id)))
cat(paste0(sprintf("Progress: %.4f%%             ", it), "\r"))
d[[x]] <- get_question(questionid = x, good_manners = 0)
#paste0("stortingsporsmal", x) = rbind(a, b, c)
}
View(plot3)
View(d)
questiontext <- do.call("rbind", d)
View(questiontext)
sum(is.na(questiontext$answer_text))
questiontext$answer_text[1]
questiontext$answer_text[2]
questiontext$answer_text[17641]
?do.call
str_detect_all(questiontext$question_text)
str_detect(questiontext$question_text)
str_detect(questiontext$question_text, "FN sambandet")
sum(str_detect(questiontext$question_text, "FN sambandet"))
sum(str_detect(questiontext$question_text, "Utdanning for Bærekraftig Utvikling"))
sum(str_detect(questiontext$question_text, "delmål 4.7"))
sum(str_detect(questiontext$question_text, "FN"))
sum(str_detect(questiontext$question_text, "FN-sambandet"))
sum(str_detect(questiontext$question_text, "UBU"))
sum(str_detect(questiontext$question_text, "4.7"))
sum(str_detect(questiontext$answer_text, "4.7"))
sum(str_detect(questiontext$answer_text, "UBU"))
sum(str_detect(questiontext$answer_text, "utdanning for bærekraftig utvikling"))
sum(str_detect(questiontext$answer_text, "FN-sambandet"))
which(str_detect(questiontext$answer_text, "FN-sambandet"))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, message = FALSE)
library(rvest)
library(stringr)
song_page <- read_html("https://www.westsidestory.com/lyrics") # Read the html page
songs <- song_page %>%
html_nodes("h2") %>% # Extract all html-nodes with the tag <h2>
html_elements("a") %>% # Extract from this node all html-tags with <a>
html_attr("href") %>% # And from these, the text belonging to the link reference <href>
str_c("https://www.westsidestory.com", .)  # Paste together the previous webpage string with these
headline <- str_remove_all(songs, "https://www.westsidestory.com/") # Extracting the name of the songs
setwd("~/ISSSV1337")
for(i in 1:length(songs)) { # For all the links to the different songs...
download.file(songs[[i]], # Download one html-file after another into the folder specified in destfile
destfile = str_c("./ws_songs/", headline[i], ".html"))
}
songfiles <- list.files("./ws_songs/") %>%
str_c("./ws_songs/", .) # Listing up the html-files in the folder
songname <- list() # Make an empty list for the songnames
ws_lyrics <- list() # Make an empty list for the lyrics
for(i in 1:length(songfiles)){ # For each file in the folder as listed
songname[[i]] <- songfiles[i] %>%
str_remove("./ws_songs/") %>% # Remove the beginning of the file string
str_remove("\\.html") # Remove the end - leaving us with just the name of the song
lyric <- read_html(songfiles[i]) # Read the html-page
lyric <- lyric %>%
html_node("p") %>% # Extract all nodes with the tag <p>
html_text2() # Fetch the text from these tags
ws_lyrics[[i]] <- lyric # Add the lyrics to the empty list
}
ws_lyrics <- str_replace_all(ws_lyrics, "\n", " ") # Replacing double lineshift with space to make the next code work
ws_lyrics <- str_remove_all(ws_lyrics, "\\b[A-Z]{2,}\\b") # Remove all sequences of big letters followed by lineshift, as they are names of who's singing
westside <- as_tibble(list(songname = unlist(songname), # Put the songnames into a column in a tibble
lyrics = unlist(ws_lyrics))) # Put the lyrics into a column in a tibble
glimpse(westside)
library(tidytext)
westside_tokens <- westside %>%
unnest_tokens(input = lyrics, # Which variable to get the text from
output = word, # What the new variable should be called
token = "words") # Type of tokens to split the text into
westside_tokens
westside %>%
unnest_tokens(input = lyrics,
output = word,
token = "ngrams",
n = 2)
westside %>%
unnest_tokens(input = lyrics,
output = word,
token = "sentences")
# Counting the number of words per songsame and sorting from highest to lowest
westside_tokens %>%
count(songname, word, sort = TRUE)
tidytext::stop_words # A dataframe with stopwords within the tidytext package
westside_tokens <- westside_tokens %>%
anti_join(stop_words, by = "word") # Joining against the stopwords dataframe to get rid of cells with stopwords
westside_tokens %>%
count(songname, word, sort = TRUE)
library(SnowballC)
westside_tokens <- westside_tokens %>%
mutate(stem = wordStem(word))
westside_tokens
plot_df <- westside_tokens %>% # Make a new dataframe to plot
count(songname, stem) %>% # Counting the number of words per songname
group_by(songname) %>% # Grouping by songname and...
slice_max(n, n = 5) %>% # Taking out the five top most used words per songname
ungroup() # Ungrouping to get the dataframe back to normal
plot_df %>%
ggplot(aes(n, fct_reorder(stem, n), # Placing number of occurences (n) on the x-axis and word on the y-axis
fill = songname)) + # Adding colors to the bars after the songname
geom_bar(stat = "identity") + # Making a barplot where the y-axis is the measure (stat = "identity")
facet_wrap(~ songname, ncol = 4, scales = "free") + # Making one small plot per songname, arranging them in three columns and let the y-axis vary independent of the other plots
labs(x = "", y = "") + # Removing all labels on x- and y-axis
theme_bw() + # Make the background white
theme(legend.position = "none") # Removing the legend for what colors mean
library(wordcloud) # Loading one package that we can use to make wordclouds
wordcloud_df <- westside_tokens %>%
count(songname, stem) # Counting the number of words per songname
wordcloud_df %>%
with(wordcloud(stem, n, # Making a wordcloud with the words weighed by how frequent they are
max.words = 100, # Plotting maximum 100 words to not make the plot too big
colors = brewer.pal(8, "Dark2")[factor(westside_tokens$songname)])) # Coloring the words after which songname they come from
library(quanteda)
westside_tokens %>%
count(songname, stem, name = "count") %>% # By default, the count-variable is called "n". Use name = "" to change it.
cast_dfm(songname, # Specify the douments in your analysis (becoming the rows)
stem, # Specify the tokens in your analysis (becoming the columns)
count) # Specify the number of times each token shows up in each document (becoming the cells)
westside_tokens <- westside_tokens %>%
count(songname, stem, name = "count") %>%
bind_tf_idf(stem, songname, count) # Making the tf-idf measure
westside_tokens
plot_df_tfidf <- westside_tokens %>%
group_by(songname) %>%
slice_max(tf_idf, n = 5) %>% # Get the five highest units on the tf-idf measure
ungroup()
plot_df_tfidf %>%
ggplot(aes(tf_idf, fct_reorder(stem, tf_idf), # Plotting words based on their tf-idf score
fill = songname)) +
geom_bar(stat = "identity") +
facet_wrap(~ songname, ncol = 4, scales = "free") +
labs(x = "", y = "") +
theme_bw() +
theme(legend.position = "none")
plot_df_tfidf <- westside_tokens %>%
group_by(songname) %>%
slice_max(tf_idf, n = 5) %>% # Get the five highest units on the tf-idf measure
ungroup()
plot_df_tfidf %>%
ggplot(aes(tf_idf, fct_reorder(stem, tf_idf), # Plotting words based on their tf-idf score
fill = songname)) +
geom_bar(stat = "identity") +
facet_wrap(~ songname, ncol = 4, scales = "free") +
labs(x = "", y = "") +
theme_bw() +
theme(legend.position = "none")
westside_tokens %>%
cast_dfm(songname,
stem,
tf_idf) # Specify tf-idf
saveRDS(westside_tokens, file = "./westside_tokens.rds")
questionsFN <- questiontext %>%
filter(str_detect(questiontext$question_text, "FN-sambandet"))
View(questionsFN)
questionsFN$answer_text
sum(str_detect(questiontext$question_text, "berekraftsmål"))
sum(str_detect(questiontext$answer_text, "berekraftsmål"))
sum(str_detect(questiontext$answer_text, "berekraftsmål$"))
sum(str_detect(questiontext$question_text, "^berekraftsmål"))
sum(str_detect(questiontext$answer_text, "^berekraftsmål"))
sum(str_detect(questiontext$question_text, "berekraftsmål+"))
sum(str_detect(questiontext$answer_text, "berekraftsmål+"))
sum(str_detect(questiontext$answer_text, "berekraftsmåla"))
sum(str_detect(questiontext$answer_text, "berekraftsmåla"))
View(questiontext)
get_session_decisions(sessionid = "2021-2022", good_manners = 0)
vedtak <- get_session_decisions(sessionid = "2021-2022", good_manners = 0)
View(vedtak)
vedtak2 <- get_vote(caseid = "40028833", good_manners = 0)
View(vedtak2)
vedtak2 <- get_vote(caseid = "40029298", good_manners = 0)
questionstest <- get_session_questions(sessionid = "2007-2008", q_type = "interpellasjoner", status = NA, good_manners = 0)
View(vedtak2)
sum(str_detect(questiontext$question_text, "FN+"))
sum(str_detect(questiontext$question_text, "FN"))
sum(str_detect(questiontext$answer_text, "berekrafts"))
sum(str_detect(questiontext$answer_text, "berekraftsm"))
sum(str_detect(questiontext$answer_text, "å"))
sum(str_detect(questiontext$answer_text, "bærekraft"))
str_detect(vedtak$decision_title, "Representantforslag om lønnsmoderasjon for høytlønnede i staten
")
sum(str_detect(vedtak$decision_title, "Representantforslag om lønnsmoderasjon for høytlønnede i staten"))
sum(str_detect(questiontext$answer_text,"^bærekraft"))
sum(str_detect(questiontext$answer_text,"berekraft"))
encoding(questiontext)
encoding(questiontext$question_text)
sum(str_detect(questiontext$answer_text,"bærekraft"))
sum(str_detect(questiontext$answer_text,"æ"))
sum(str_detect(questiontext$answer_text,"Samfunnsøkonomisk"))
sum(grepl("Samfunnsøkonomisk", questiontext$question_text))
str_detect(questiontext$answer_text,"Samfunnsøkonomisk")
object <- "sær"
str_detect(object, "æ")
print(questiontext$question_text[5])
str_detect(questiontext$question_text[5], "æ")
encoding(questiontext$question_text[5])
str_detect(questiontext$question_text[5], "undersøker")
str_detect(questiontext$question_text[5], "undersoker")
str_detect(questiontext$question_text[5], "[æøå]")
print("æøå")
print(object)
print("æøå")
print("æøå")
print("æøå")
source("~/Group-3-ISSSV1337/QuestionsScraping.R", encoding = 'UTF-8')
print("æøå")
encoding(object)
object <- "sære kår lever ørt"
encoding(object)
print(object)
object <- "sære kår lever ørt"
print(object)
encoding(object)
object <- "sære kår lever ørt"
print(object)
source("~/Group-3-ISSSV1337/QuestionsScraping.R", encoding = 'UTF-8')
Sys.getlocale()
Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
Sys.getlocale()
?Sys.setlocale
Sys.setenv(LANG = "en_US.UTF-8")
print("æøå")
print(object)
object <- "sære kår lever ørt"
print(object)
Sys.setlocale("LC_ALL", "Norwegian")
object <- "sære kår lever ørt"
print(object)
Sys.getlocale()
Sys.setlocale("LC_ALL", "")
Sys.getlocale()
object <- "sære kår lever ørt"
print(object)
sum(grepl("Samfunnsøkonomisk", questiontext$question_text))
sum(str_detect(questiontext$question_text, "bærekraftig utdanning"))
sum(str_detect(questiontext$question_text, "Bærekraftig utdanning"))
sum(str_detect(questiontext$question_text, "UBU"))
print(questiontext$question_text[which(str_which(questiontext$question_text, "UBU"))])
questiontext$question_text[which(str_which(questiontext$question_text, "UBU"))]
questiontext$question_text[str_which(questiontext$question_text, "UBU")]
questiontext$question_text[str_which(questiontext$question_text, "4.7")]
sum(str_detect(questiontext$question_text, "bærekraftig utdanning"))
sum(str_detect(questiontext$question_text, "Bærekraftig utdanning"))
sum(str_detect(questiontext$question_text, "FN-sambandet"))
setwd("~/Group-3-ISSSV1337")
save(questionlist, file = "Question_Data/MetadataQuestionList.Rdata")
save(questiontext, file = "Question_Data/All_Questions.Rdata")
rm(list = ls())
